library(tm)
library(wordcloud)
library(stringr)
library(rtweet)
app='buahbolo'
consumer_key <- 'sX7trRCT70nVkc8qBaFEKI4sF'
consumer_secret <- 'whqwp3MXXQYhhzRJEAVKkyXM8Gb3bnDJb9kuKXRTWtezNOFIRZ'
access_token <- '277948939-RiSj8sVWBGrYUWwsIPTVcMve2Lw5nLT4XkLD6kgI'
access_secret <- 'WXHZYR3k8wCybEWueIz0NYTOnWp29BSxHos5iq4huf3IL'
create_token(app = app,consumer_key = consumer_key,consumer_secret = consumer_secret, access_token = access_token,access_secret = access_secret)
twt=search_tweets(q="#CPNS2018 OR #cpns OR #cpns2018 OR #CPNS OR cpns",n=50000,include_rts=FALSE,type="recent",retryonratelimit = TRUE,lang="id")
length(twt$text)
twt$text[1:5]
twt$text[5:10]
View(twt)
library(data.table)
names(twt)
sapply(as.factror(twt$source),levels)
sapply(as.factor(twt$source),levels)
g=as.factor(twt$source)
sapply(g,levels)
str(g)
levels(g)
levels(twt$source)
twt$text[twt$source=="twittbot.net"][1:5]
length(twt$text[twt$source=="twittbot.net"])
twt$text[twt$source=="twittbot.net"][100:105]
twt$text[twt$source=="twittbot.net"][190:197]
twt$text[twt$source=="AJNN.net"][1:5]
twt$text[twt$source=="AJNN.net"][5:10]
twt$text[twt$source==levels(twt$source[1])][1:5]
twt$text[twt$source==levels(twt$source)[1]][1:5]
twt$text[twt$source==levels(twt$source)[2]][1:5]
levels(twt$source)
twt$text[twt$source==levels(g)[1]][1:5]
twt$text[twt$source==levels(g)[2]][1:5]
twt$text[twt$source==levels(g)[3]][1:5]
twt$text[twt$source==levels(g)[4]][1:5]
twt$text[twt$source==levels(g)[5]][1:5]
twt$text[twt$source==levels(g)[6]][1:5]
twt$text[twt$source==levels(g)[6]][1:6]
twt$text[twt$source==levels(g)[7][1:6]
}
twt$text[twt$source==levels(g)[7]][1:6]
twt$text[twt$source==levels(g)[8]][1:6]
twt$text[twt$source==levels(g)[9]][1:6]
twt$text[twt$source==levels(g)[10]][1:6]
twt$text[twt$source==levels(g)[11]][1:6]
twt$text[twt$source==levels(g)[12]][1:6]
twt$text[twt$source==levels(g)[13]][1:6]
twt$text[twt$source==levels(g)[14]][1:6]
twt$text[twt$source==levels(g)[15]][1:6]
twt$text[twt$source==levels(g)[16]][1:6]
twt$text[twt$source==levels(g)[17]][1:6]
twt$text[twt$source==levels(g)[18]][1:6]
twt$text[twt$source==levels(g)[19]][1:6]
twt$text[twt$source==levels(g)[20]][1:6]
levels(g)[20]
twt$text[twt$source==levels(g)[21]][1:6]
levels(g)[21]
twt$text[twt$source==levels(g)[22]][1:6]
twt$text[twt$source==levels(g)[23]][1:6]
twt$text[twt$source==levels(g)[24]][1:6]
twt$text[twt$source==levels(g)[25]][1:6]
twt$text[twt$source==levels(g)[26]][1:6]
twt$text[twt$source==levels(g)[27]][1:6]
twt$text[twt$source==levels(g)[28]][1:6]
twt$text[twt$source==levels(g)[29]][1:6]
twt$text[twt$source==levels(g)[30]][1:6]
twt$text[twt$source==levels(g)[31]][1:6]
twt$text[twt$source==levels(g)[32]][1:6]
twt$text[twt$source==levels(g)[33]][1:6]
twt$text[twt$source==levels(g)[34]][1:6]
twt$text[twt$source==levels(g)[35]][1:6]
twt$text[twt$source==levels(g)[36]][1:6]
twt$text[twt$source==levels(g)[37]][1:6]
twt$text[twt$source==levels(g)[38]][1:6]
twt$text[twt$source==levels(g)[39\]][1:6]
twt$text[twt$source==levels(g)[39]][1:6]
twt$text[twt$source==levels(g)[40]][1:6]
twt$text[twt$source==levels(g)[41]][1:6]
twt$text[twt$source==levels(g)[42]][1:6]
twt$text[twt$source==levels(g)[43]][1:6]
twt$text[twt$source==levels(g)[44]][1:6]
twt$text[twt$source==levels(g)[45]][1:6]
twt$text[twt$source==levels(g)[46]][1:6]
twt$text[twt$source==levels(g)[47]][1:6]
twt$text[twt$source==levels(g)[48]][1:6]
twt$text[twt$source==levels(g)[49]][1:6]
twt$text[twt$source==levels(g)[50]][1:6]
twt$text[twt$source==levels(g)[51]][1:6]
twt$text[twt$source==levels(g)[52]][1:6]
twt$text[twt$source==levels(g)[53]][1:6]
levels(g)[53]
twt$text[twt$source==levels(g)[54]][1:6]
twt$text[twt$source==levels(g)[55]][1:6]
twt$text[twt$source==levels(g)[56]][1:6]
twt$text[twt$source==levels(g)[57]][1:6]
levels(g)[57]
length(twt$text[twt$source==levels(g)[57]])
twt$text[twt$source==levels(g)[58]][1:6]
twt$text[twt$source==levels(g)[59]][1:6]
twt$text[twt$source==levels(g)[60]][1:6]
twt$text[twt$source==levels(g)[61]][1:6]
twt$text[twt$source==levels(g)[62]][1:6]
twt$text[twt$source==levels(g)[63]][1:6]
length(twt$text[twt$source==levels(g)[63]])
levels(g)[63]
twt$text[twt$source==levels(g)[63]][1:10]
twt$text[twt$source==levels(g)[64]][1:10]
twt$text[twt$source==levels(g)[65]][1:10]
twt$text[twt$source==levels(g)[66]][1:10]
twt$text[twt$source==levels(g)[67]][1:10]
twt$text[twt$source==levels(g)[68]][1:10]
twt$text[twt$source==levels(g)[69]][1:10]
twt$text[twt$source==levels(g)[70]][1:10]
twt$text[twt$source==levels(g)[71]][1:10]
twt$text[twt$source==levels(g)[72]][1:10]
twt$text[twt$source==levels(g)[73]][1:10]
levels(g)[73]
length(twt$text[twt$source==levels(g)[73]])
twt$text[twt$source==levels(g)[73]][10:0]
twt$text[twt$source==levels(g)[73]][10:20]
twt$text[twt$source==levels(g)[74]][10:20]
twt$text[twt$source==levels(g)[74]][1:10]
twt$text[twt$source==levels(g)[75]][1:10]
twt$text[twt$source==levels(g)[76]][1:10]
twt$text[twt$source==levels(g)[77]][1:10]
twt$text[twt$source==levels(g)[78]][1:10]
twt$text[twt$source==levels(g)[79]][1:10]
twt$text[twt$source==levels(g)[80]][1:10]
twt$text[twt$source==levels(g)[81]][1:10]
twt$text[twt$source==levels(g)[100]][1:10]
twt$text[twt$source==levels(g)[101]][1:10]
twt$text[twt$source==levels(g)[102]][1:10]
twt$text[twt$source==levels(g)[104]][1:10]
twt$text[twt$source==levels(g)[106]][1:10]
twt$text[twt$source==levels(g)[108]][1:10]
twt$text[twt$source==levels(g)[109]][1:10]
twt$text[twt$source==levels(g)[110]][1:10]
twt$text[twt$source==levels(g)[111]][1:10]
twt$text[twt$source==levels(g)[112]][1:10]
gc()
save.image("D:/kampus/kerja/twt/data.RData")
names(twt)
ts_plot(twt,by="days")
levels(g)
length(twt$text[twt$source=="Twitter for Android"])
length(twt$text[twt$source=="Twitter for iphone"])
length(twt$text[twt$source=="Twitter for iPhone"])
twt$text[twt$source=="Twitter for iPhone"][1:5]
twt$text[twt$source=="Twitter for Android"][1:5]
names(twt)
View(twt)
levels(g)
qq=c("aku suka kamu","dia suka kamu")
cc=gsub("aku suka","iya",qq)
cc
qq=c("aku suka kamu","dia suka kamu","aku")
cc=gsub("aku suka","iya",qq)
cc
twt$text[twt$source==levels(g)[203]][1:10]
twt$text[twt$source==levels(g)[203]][10:20]
twt$text[twt$source==levels(g)[203]][20:30]
twt$text[twt$source==levels(g)[203]][31:40]
twt$text[twt$source==levels(g)[203]][41:50]
twt$text[twt$source==levels(g)[203]][51:60]
twt$text[twt$source==levels(g)[203]][61:70]
twt$text[twt$source==levels(g)[203]][71:80]
twt$text[twt$source==levels(g)[203]][81:90]
twt$text[twt$source==levels(g)[203]][90:100\]
twt$text[twt$source==levels(g)[203]][90:100]
twt$text[twt$source==levels(g)[203]][100:101]
twt$text[twt$source==levels(g)[203]][100:110]
twt$text[twt$source==levels(g)[203]][110:120]
twt$text[twt$source==levels(g)[203]][121:130]
twt$text[twt$source==levels(g)[203]][131:140]
twt$text[twt$source==levels(g)[203]][141:150]
twt$text[twt$source==levels(g)[203]][151:161]
twt$text[twt$source==levels(g)[203]][161:171]
twt$text[twt$source==levels(g)[203]][171:181]
twt$text[twt$source==levels(g)[203]][181:191]
twt$text[twt$source==levels(g)[203]][191:210]
twt$text[twt$source==levels(g)[203]][210:221]
twt$mentions_screen_name[1:5]
twt$reply_to_screen_name[1:5]
twt$reply_to_screen_name[1:6]
twt$text[1]
twt$mentions_screen_name[1]=="BKNgoid"
twt$mentions_screen_name[2]=="BKNgoid"
twt$mentions_screen_name[3]=="BKNgoid"
twt$mentions_screen_name[1]
class(twt$mentions_screen_name[1])
unlist(twt$mentions_screen_name[1])
unlist(twt$mentions_screen_name[1])=="BKNgoid"
twt$text[unlist(twt$mentions_screen_name)=="BKNgoid"][1]
isTRUE(unlist(twt$mentions_screen_name)[1]=="BKNgoid")
isTRUE(unlist(twt$mentions_screen_name)[2]=="BKNgoid")
class(unlist(twt$mentions_screen_name[1]))
is.vector((unlist(twt$mentions_screen_name[1])))
as.vector((unlist(twt$mentions_screen_name[1])))
isTRUE(as.vector((unlist(twt$mentions_screen_name[1])))[1]=="BKNgoid")
isTRUE(as.vector((unlist(twt$mentions_screen_name[1])))=="BKNgoid")
isTRUE(as.vector((unlist(twt$mentions_screen_name[2])))=="BKNgoid")
sapply(1:length(twt$mentions_screen_name[1]),twt$mentions_screen_name[1],function (x) isTRUE(x)=="BKNgoid")
sapply(twt$mentions_screen_name[1],function (x) isTRUE(x)=="BKNgoid")
sapply(unlist(twt$mentions_screen_name[1]),function (x) isTRUE(x)=="BKNgoid")
sapply(unlist(twt$mentions_screen_name[1]),function (x) isTRUE(x=="BKNgoid"))
sum(sapply(unlist(twt$mentions_screen_name[1]),function (x) isTRUE(x=="BKNgoid")))
sum(sapply(unlist(twt$mentions_screen_name[2]),function (x) isTRUE(x=="BKNgoid")))
sum(sapply(unlist(twt$mentions_screen_name[4]),function (x) isTRUE(x=="BKNgoid")))
sum(sapply(unlist(twt$mentions_screen_name[5]),function (x) isTRUE(x=="BKNgoid")))
id=c()
for (i in 1:dim(twt)[1]){
if (sum(sapply(unlist(twt$mentions_screen_name[i]),function (x) isTRUE(x=="BKNgoid")))==1) {id[i]=i}
else {id[i]=0}
}
id[1:10]
id[10:100]
id=id[id!=0]
head(id,20)
teks.to.bkn=twt$text[id]
teks.to.bkn[1:5]
load("D:/kampus/kerja/twt/data.RData")
kk=read.csv2(choose.files())
head(kk)
kk=read.csv2(choose.files(),header=FALSE)
head(kk)
class(kk)
kk[1,1]
as.character(kk)
hh=as.character(kk)
hh
kk
readLines(kk)
readLines(choose.files())
readLines(choose.files())
read.delim(choose.files())
read.delim(choose.files(),sep="",header=FALSE)
kk=read.csv2(choose.files(),header=FALSE,sep="")
kk
kk=read.csv2(choose.files(),header=FALSE,sep=";")
kk
kk[1,1]
kk=read.table(choose.files(),header=FALSE)
kk=read.csv2(choose.files(),header=FALSE,sep=";")
kk
kk[1,2]
kk[1,1]
as.character(kk)
as.character(kk[1,1])
knitr::opts_chunk$set(echo = TRUE)
dat100=tes[1:100]
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(wordcloud)
library(stringr)
library(rtweet)
library(wordcloud2)
library(data.table)
library(proxy)
library(Rgraphviz)
library(graph)
library(ggplot2)
library(DT)
load("D:/kampus/kerja/twt/data.RData")
indeks=function(user){
id=c()
for (i in 1:dim(twt)[1]){
if (sum(sapply(unlist(twt$mentions_screen_name[i]),function (x) isTRUE(x==user)))==1) {id[i]=i}
else {id[i]=0}
}
id=id[id!=0]
return(id)
}
id=indeks("BKNgoid")
tes=as.data.table(twt)
tes1=tes[,.(created_at,text)]
tes1$created_at=as.Date(tes1$created_at)
tes1=tes1[,.N,by=.(created_at)]
tes2=tes[id,.(created_at,text)]
tes2$created_at=as.Date(tes2$created_at)
tes2=tes2[,.N,by=.(created_at)]
ggplot(data=tes1,aes(x=created_at,y=N))+geom_line(aes(color="Total Tweet"))+geom_line(data=tes2,aes(color="Mention ke BKN"))+xlab("tanggal")+ylab("Jumlah Tweet")+labs(color="Legend text")
tweet.user=tes[,.(created_at,screen_name,text)]
tweet.user$created_at=as.Date(tweet.user$created_at)
tweet.user1=tweet.user[,.N,by=.(screen_name)]
tweet.user1=tweet.user1[order(N,decreasing = TRUE)]
ggplot(tweet.user1[N>30],aes(fill=screen_name,x=screen_name,y=N))+geom_bar(stat="identity")+theme(axis.text.x = element_blank()) + ggtitle("Jumlah Tweet Terbanyak Berdasarkan Username")+xlab("Nama akun")
teks=twt$text
teks=gsub("http[^[[:space:]]*","",teks)
teks=gsub("@\\w+", "", teks)
teks=gsub("[^[:alpha:][:space:]]*","",teks)
teks=gsub("[[:punct:]]", "", teks)
teks=str_replace_all(teks,"#[a-z,A-Z]*","")
teks=tolower(teks)
kk=read.csv2(choose.files(),header=FALSE)
for (i in 1:nrow(kk)){
teks=gsub(as.character(kk[i,1]),as.character(kk[i,2]),teks)
}
url="https://raw.githubusercontent.com/nurandi/snippet/master/data/stopwords-id.txt"
stopword=readLines(url)
stopword=c(stopword,"kali","admin","sbg","haha","klo","dasar","kompetensi","dpt","cpns","biar","dri","nih","lho","dah","terus","iii","hai","via","utk","ternyata","kah","tau","sih","kab","tahu","sdh","krn","aja","untuk","kalo","atas","min","udah","mlm","tgl","berikut","tag","kaka","dlu","mimin","blm","ayo","yah","mari","gue","yaa","ane","yuk","nya","dgn","sdh","skrg","guys","kau","dimana","yaaa","#bkngoid","jadiasn","jadi","tahun","orang","kota","hari","amp","jam","terbaru","besok","naar","pagi","teman","mas","pak","tanggal","baru","pertama","terima","lewat","mulai","kak","pas","terimakasih","satu","masuk","mba","kemarin","sampe","soalnya","menjadi","mbak","iya","banget","udh","malam","gitu","kabupaten","seleksi","tdk","gak","calon","org","thn","kakak","pake","jga","cma","dlm","msh","bro","taun","askmiminbkngoid")
tweets.teks.corpus <- Corpus(VectorSource(teks))
a=tm_map(tweets.teks.corpus, function(x)removeWords(x,stopword))
a=tm_map(a, stripWhitespace)
a=tm_map(a, removeNumbers)
tdm=TermDocumentMatrix(a)
tdm1=removeSparseTerms(tdm,0.999)
m=as.matrix(tdm1)
v=sort(rowSums(m),decreasing=TRUE)
d=data.table(word = names(v),freq=v)
ggplot(d[freq>=230],aes(x=word,y=freq))+geom_bar(stat="identity",aes(fill=freq))+xlab("KATA")+ylab("JUMLAH")+coord_flip()
wordcloud2(d,size=1.5)
freq.terms=findFreqTerms(tdm1,lowfreq = 280)
plot(tdm1,term=freq.terms,corThreshold=0.05,weighting=T,main="network of words freq > 280")
findAssocs(tdm1, terms = "lulus", corlimit = 0.1)
findAssocs(tdm1, terms = "skd", corlimit = 0.1)
findAssocs(tdm1, terms = "tkp", corlimit = 0.1)
dat100=tes[1:100]
datatable(dat100, rownames = FALSE, filter="top", escape=FALSE, options = list(pageLength = 5, scrollX=T))
dat100=tes[1:100]
datatable(dat100, rownames = FALSE)
dat100=tes[1:100]
datatable(dat100, rownames = FALSE, filter="top", escape=FALSE, options = list(pageLength = 5, scrollX=T))
dat100=tes[1:100]
datatable(dat100, rownames = FALSE,options = list(pageLength = 5, scrollX=T))
dat100=tes[1:100]
datatable(dat100)
dat100=tes[1:100]
datatable(dat100,rownames = FALSE)
dat100=tes[1:100]
datatable(as.data.frame(dat100),rownames = FALSE)
dat100=tes[1:100]
datatable(dat100, rownames = FALSE, filter="top", escape=FALSE, options = list(pageLength = 5, scrollX=T))
datatable(iris, rownames = FALSE, filter="top", escape=FALSE, options = list(pageLength = 5, scrollX=T))
dat100=tes[1:50]
datatable(dat100, rownames = FALSE, filter="top", escape=FALSE, options = list(pageLength = 5, scrollX=T))
datatable(iris)
library(devtools)
install_github('rstudio/rmarkdown#1153')
install_github('rstudio/rmarkdown#1153')
datatable(dat100, rownames = FALSE, filter="top", escape=FALSE, options = list(pageLength = 5, scrollX=T))
